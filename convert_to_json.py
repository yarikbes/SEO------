"""–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ CSV –≤ slugs.json.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python convert_to_json.py [input_csv] [output_json]

–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —á–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª "URL –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö - –í–∞—Ä–∏–∞–Ω—Ç –ë (—Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π).csv"
–≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞ –∏ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç slugs.json.
"""
from __future__ import annotations

import json
import sys
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Dict, Iterable, List

import pandas as pd

ROOT = Path(__file__).resolve().parent
DEFAULT_INPUT = ROOT / "URL –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö - –í–∞—Ä–∏–∞–Ω—Ç –ë (—Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π).csv"
DEFAULT_OUTPUT = ROOT / "slugs.json"

PAGE_GROUPS = {
    "main": {"description": "–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞", "aliases": ["", "/"]},
    "privacy": {"description": "–ü–æ–ª–∏—Ç–∏–∫–∞ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏", "aliases": ["privacy", "privacy-policy", "privacy-notice"]},
    "terms": {"description": "–£—Å–ª–æ–≤–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è", "aliases": ["terms", "terms-condition"]},
    "responsible": {"description": "–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–∞—è –∏–≥—Ä–∞", "aliases": ["responsible", "responsible-gaming"]},
    "cookies": {"description": "–ü–æ–ª–∏—Ç–∏–∫–∞ cookies", "aliases": ["cookies-policy", "cookies"]},
    "kyc": {"description": "–ü–æ–ª–∏—Ç–∏–∫–∞ KYC"},
    "faq": {"description": "–ß–∞—Å—Ç–æ –∑–∞–¥–∞–≤–∞–µ–º—ã–µ –≤–æ–ø—Ä–æ—Å—ã"},
    "contacts": {"description": "–ö–æ–Ω—Ç–∞–∫—Ç—ã"},
    "support": {"description": "–ü–æ–¥–¥–µ—Ä–∂–∫–∞"},
    "login": {"description": "–í—Ö–æ–¥ –≤ —Å–∏—Å—Ç–µ–º—É"},
    "bonus": {"description": "–ë–æ–Ω—É—Å—ã"},
    "promoCode": {"description": "–ü—Ä–æ–º–æ–∫–æ–¥ / –ë–æ–Ω—É—Å –∫–æ–¥", "aliases": ["promo-code", "bonus-code"]},
    "noDepositBonus": {"description": "–ë–æ–Ω—É—Å –±–µ–∑ –¥–µ–ø–æ–∑–∏—Ç–∞"},
    "review": {"description": "–û–±–∑–æ—Ä –∫–∞–∑–∏–Ω–æ"},
    "withdrawal": {"description": "–í—ã–≤–æ–¥ —Å—Ä–µ–¥—Å—Ç–≤"},
    "freeSpins": {"description": "–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –≤—Ä–∞—â–µ–Ω–∏—è"},
    "app": {"description": "–ú–æ–±–∏–ª—å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ"},
    "games": {"description": "–ò–≥—Ä—ã"},
    "lottery": {"description": "–õ–æ—Ç–µ—Ä–µ—è"},
    "vipProgram": {"description": "VIP –ø—Ä–æ–≥—Ä–∞–º–º–∞"},
    "verification": {"description": "–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è"},
    "cashback": {"description": "–ö—ç—à–±—ç–∫"},
    "sport": {"description": "–°–ø–æ—Ä—Ç"},
    "betting": {"description": "–°—Ç–∞–≤–∫–∏ –Ω–∞ —Å–ø–æ—Ä—Ç", "aliases": ["betting", "sports-betting"]},
    "slots": {"description": "–°–ª–æ—Ç—ã", "aliases": ["slots", "online-slots"]},
    "rules": {"description": "–ü—Ä–∞–≤–∏–ª–∞", "aliases": ["regler"]},
}

TYPE_TO_GROUP = {
    "": "main",
    "/": "main",
    "main": "main",
    "en-gb": "main",
    "privacy": "privacy",
    "privacy-policy": "privacy",
    "privacy-notice": "privacy",
    "terms": "terms",
    "terms-condition": "terms",
    "responsible": "responsible",
    "responsible-gaming": "responsible",
    "cookies": "cookies",
    "cookies-policy": "cookies",
    "kyc": "kyc",
    "faq": "faq",
    "contacts": "contacts",
    "support": "support",
    "login": "login",
    "bonus": "bonus",
    "promo-code": "promoCode",
    "bonus-code": "promoCode",
    "no-deposit-bonus": "noDepositBonus",
    "review": "review",
    "withdrawal": "withdrawal",
    "free-spins": "freeSpins",
    "app": "app",
    "games": "games",
    "lottery": "lottery",
    "vip-program": "vipProgram",
    "verification": "verification",
    "cashback": "cashback",
    "sport": "sport",
    "betting": "betting",
    "sports-betting": "betting",
    "slots": "slots",
    "online-slots": "slots",
    "rules": "rules",
}


@dataclass
class PageBlock:
    slug: str
    rows: List[pd.Series]


def load_blocks(df: pd.DataFrame) -> Iterable[PageBlock]:
    current_slug: str | None = None
    buffer: List[pd.Series] = []

    for _, row in df.iterrows():
        first = str(row.iloc[0]).strip() if pd.notna(row.iloc[0]) else ""
        if first.startswith('/'):
            if current_slug and buffer:
                yield PageBlock(current_slug, buffer)
                buffer = []
            current_slug = first
        if current_slug:
            buffer.append(row)

    if current_slug and buffer:
        yield PageBlock(current_slug, buffer)


def clean_slug(raw: str) -> str:
    slug = raw.strip()
    if not slug:
        return '/'
    if not slug.startswith('/'):
        slug = '/' + slug
    return '/' + slug.strip('/').lower()


def resolve_group(slug: str) -> str:
    key = slug.lstrip('/')
    return TYPE_TO_GROUP.get(slug) or TYPE_TO_GROUP.get(key) or key


def block_entries(block: PageBlock, headers: List[str]) -> Dict[str, str]:
    entries: Dict[str, str] = {}
    for row in block.rows:
        for idx, value in enumerate(row):
            if idx >= len(headers):
                continue
            if pd.isna(value) or not str(value).strip():
                continue
            entries[clean_slug(str(value))] = headers[idx]
    return entries


def build_groups(blocks: Iterable[PageBlock], headers: List[str]) -> Dict[str, Dict[str, Dict[str, str]]]:
    groups: Dict[str, Dict[str, Dict[str, str]]] = {}
    for block in blocks:
        group_key = resolve_group(block.slug)
        entries = block_entries(block, headers)
        bucket = groups.setdefault(group_key, {"slugs": {}})
        bucket["slugs"].update(entries)
    return groups


def merge_with_metadata(groups: Dict[str, Dict[str, Dict[str, str]]]) -> Dict[str, Dict[str, object]]:
    merged: Dict[str, Dict[str, object]] = {}
    for key, info in groups.items():
        meta = PAGE_GROUPS.get(key, {"description": key})
        merged[key] = {
            "description": meta["description"],
            "slugs": dict(sorted(info["slugs"].items())),
        }
        if aliases := meta.get("aliases"):
            merged[key]["aliases"] = aliases
    return dict(sorted(merged.items()))


def convert(input_path: Path, output_path: Path) -> None:
    df = pd.read_csv(input_path, header=None)
    headers = [str(col).strip() for col in df.iloc[1]]
    payload = df.iloc[2:].reset_index(drop=True)
    blocks = list(load_blocks(payload))
    raw_groups = build_groups(blocks, headers)
    final_groups = merge_with_metadata(raw_groups)

    data = {
        "version": "2.7",
        "updated": datetime.now().strftime("%Y-%m-%d"),
        "pageGroups": final_groups,
    }
    output_path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")

    print(f"‚úÖ JSON —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path}")
    print(f"üß© –ì—Ä—É–ø–ø: {len(final_groups)}")
    print(f"üî¢ –°–ª–∞–≥–æ–≤: {sum(len(group['slugs']) for group in final_groups.values())}")


def main(args: List[str]) -> int:
    input_path = Path(args[0]).expanduser() if args else DEFAULT_INPUT
    output_path = Path(args[1]).expanduser() if len(args) > 1 else DEFAULT_OUTPUT
    if not input_path.exists():
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_path}", file=sys.stderr)
        return 1
    convert(input_path, output_path)
    return 0


if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))
